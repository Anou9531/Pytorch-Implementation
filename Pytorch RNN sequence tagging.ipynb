{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import operator\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN intuition\n",
    "\n",
    "Let us assume that we have an input $x = [x_1, x_2, ..., x_N]$ and we need to learn the mapping for some output $y = [y_1, y_2, ..., y_N]$, where $N$ is variable for each instance. In this case we can't just use a simple feed forward neural network which maps $x \\rightarrow y$, as this will not work with variable length sequences. Furthermore, the number or parameters required for training such a network would be proportional to $size(x_i)*N$. This is a major memory cost. Additionally, if the sequence has some common mapping between $x_i$ and $y_i$, then we would be learning redundant weights for each pair in the sequence. This is where an RNN network is more useful. The basic idea is that each input $x_i$ is processed in a similar fashion using the same processing module and some additional context variable (which we will henseforth refer to as the **hidden state**). This hidden state should capture some information about the part of the sequence which has already been processed. Now at each step of the sequence we need to do the following:\n",
    "\n",
    "* Generate the output based on the previous hidden state and current input\n",
    "* Update the hidden state based on the previous hidden state and current input. \n",
    "\n",
    "The order of the above steps is not fixed and forms the basis of many RNN spin-offs. What is important, at each step, is to have a new output and a new hidden state. Sometimes, the hidden state and the outputs are the same, to make the network smaller. But the core idea remains same. Below we would like to formalize the general intuition of an RNN module. \n",
    "\n",
    "Initialize an initial hidden state $h_{0}$ with some initial value. \n",
    "\n",
    "At timestep n: \n",
    "$$\n",
    "\\begin{equation}\n",
    "h^{'}_{i} = f(x_{i},h_{i})\\\\\n",
    "y_{i} = g(x_{i},h^{'}_{i})\\\\\n",
    "h_{i+1} = h^{'}_{i}\\\\\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Here $y_{i}$ is the output and $h^{'}_{i}$ is the intermediate hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Input2Hidden(nn.Module):\n",
    "    def __init__(self, x_dim, concat_layers=False):\n",
    "        \"\"\"Input2Hidden module\n",
    "        \n",
    "        Args:\n",
    "            x_dim: input vector dimension\n",
    "            concat_layers: weather to concat input and hidden layers or sum them\n",
    "        \"\"\"\n",
    "        super(Input2Hidden, self).__init__()\n",
    "        self.concat_layers = concat_layers\n",
    "        input_dim = x_dim\n",
    "        if self.concat_layers:\n",
    "            input_dim = 2*x_dim\n",
    "        self.linear_layer = nn.Linear(input_dim, x_dim)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        if self.concat_layers:\n",
    "            cell_input = torch.cat([x,h], dim=1)\n",
    "        else:\n",
    "            cell_input = x + h\n",
    "        assert isinstance(cell_input, Variable)\n",
    "        logit = F.tanh(self.linear_layer(cell_input))\n",
    "        return logit\n",
    "    \n",
    "    \n",
    "class Hidden2Output(nn.Module):\n",
    "    def __init__(self, x_dim, out_dim, concat_layers=False):\n",
    "        \"\"\"Hidden2Output module\n",
    "        \n",
    "        Args:\n",
    "            x_dim: input vector dimension\n",
    "            out_dim: output vector dimension\n",
    "            concat_layers: weather to concat input and hidden layers or sum them\n",
    "        \"\"\"\n",
    "        super(Hidden2Output, self).__init__()\n",
    "        input_dim = x_dim\n",
    "        self.concat_layers = concat_layers\n",
    "        if self.concat_layers:\n",
    "            input_dim = 2*x_dim\n",
    "        self.linear_layer = nn.Linear(input_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        if self.concat_layers:\n",
    "            cell_input = torch.cat([x,h], dim=1)\n",
    "        else:\n",
    "            cell_input = x + h\n",
    "        assert isinstance(cell_input, Variable)\n",
    "        logit = F.tanh(self.linear_layer(cell_input))\n",
    "        return logit\n",
    "    \n",
    "    \n",
    "class CustomRNNCell(nn.Module):\n",
    "    def __init__(self, i2h, h2o):\n",
    "        super(CustomRNNCell, self).__init__()\n",
    "        self.i2h = i2h\n",
    "        self.h2o = h2o\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        assert isinstance(x, Variable)\n",
    "        assert isinstance(h, Variable)\n",
    "        h_prime = self.i2h(x,h)\n",
    "        assert isinstance(h_prime, Variable)\n",
    "        output = self.h2o(x,h_prime)\n",
    "        return output, h_prime\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding, rnn_cell):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = embedding\n",
    "        self.rnn_cell = rnn_cell\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, word_ids, hidden=None):\n",
    "        if hidden is None:\n",
    "            hidden = Variable(torch.zeros(\n",
    "                word_ids.data.shape[0],self.embedding.embedding_dim))\n",
    "        assert isinstance(hidden, Variable)\n",
    "        embeddings = self.embedding(word_ids)\n",
    "        max_seq_length = word_ids.data.shape[-1]\n",
    "        outputs, hidden_states = [], []\n",
    "        for i in range(max_seq_length):\n",
    "            x = embeddings[:, i, :]\n",
    "            assert isinstance(x, Variable)\n",
    "            #print(\"x={}\\nhidden={}\".format(x,hidden))\n",
    "            output, hidden = self.rnn_cell(x, hidden)\n",
    "            assert isinstance(output, Variable)\n",
    "            assert isinstance(hidden, Variable)\n",
    "            #print(\"output: {}, hidden: {}\".format(output.data.shape, hidden.data.shape))\n",
    "            outputs.append(output.unsqueeze(1))\n",
    "            hidden_states.append(hidden.unsqueeze(1))\n",
    "        outputs = torch.cat(outputs, 1)\n",
    "        hidden_states = torch.cat(hidden_states, 1)\n",
    "        assert isinstance(outputs, Variable)\n",
    "        assert isinstance(hidden_states, Variable)\n",
    "        return outputs, hidden_states\n",
    "    \n",
    "    def loss(self, word_ids, target_ids, hidden=None):\n",
    "        outputs, hidden_states = self.forward(word_ids, hidden=hidden)\n",
    "        outputs = outputs.view(-1, outputs.data.shape[-1])\n",
    "        target_ids = target_ids.view(-1)\n",
    "        assert isinstance(outputs, Variable)\n",
    "        assert isinstance(target_ids, Variable)\n",
    "        #print(\"output={}\\ttargets={}\".format(outputs.data.shape,target_ids.data.shape))\n",
    "        loss = self.loss_function(outputs, target_ids)\n",
    "        return loss    \n",
    "        \n",
    "        \n",
    "    def predict(self, word_ids, hidden=None):\n",
    "        outputs, hidden_states = self.forward(word_ids, hidden=hidden)\n",
    "        outputs = outputs.view(-1, outputs.data.shape[-1])\n",
    "        max_scores, predictions = outputs.max(1)\n",
    "        predictions = predictions.view(*word_ids.data.shape)\n",
    "        #print(word_ids.data.shape, predictions.data.shape)\n",
    "        assert word_ids.data.shape == predictions.data.shape, \"word_ids: {}, predictions: {}\".format(\n",
    "            word_ids.data.shape, predictions.data.shape\n",
    "        )\n",
    "        return predictions\n",
    "        \n",
    "        \n",
    "def tensors2variables(*args, requires_grad=False):\n",
    "    return tuple(map(lambda x: Variable(x, requires_grad=requires_grad), args))\n",
    "\n",
    "def get_batch(tensor_types, *args, requires_grad=False):\n",
    "    return tuple(map(lambda t,arg: Variable(t(arg), requires_grad=requires_grad), tensor_types, args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to predict bit flip\n",
    "\n",
    "Let us take a simple example of using an RNN to predict the flip in bits of an $N$ bit unsigned integer. In python for an integer n represented using $N$ bits, the unsigned bitflip can be written as `(~n) & ((1<<N)-1)`. Four our RNN each bit from the left will be $x_i$ and each flipped bit will be $y_i$. This task doesn't require any temporal dependencies but will be a good exercise to test the accuracy of RNN implementation. Theoretically, the network should learn to do this job perfectly in a few iterations. Later we will move to an example which does require the network to learn some temporal dependencies between inputs. \n",
    "\n",
    "For our network we define $f(x,h)$ as a simple affine layer with $tanh$ activation, which takes the concatanated input $[x_i, h_{i-1}]$ and returns a new hidden state $h^{'}_{i}$. Similarly, we have $g(x_i, h^{'}_{n})$ also represented as an affine layer with $tanh$ activation, of the concatanation of its inputs $[x_i, h^{'}_{n}]$, resulting in a new output $y_{i}$. More formally, we have\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "h^{'}_{i} = f(x_{i},h_{i}) = \\sigma([x_i, h_{i-1}]W_{i2h})\\\\\n",
    "y_{i} = g(x_{i},h^{'}_{i}) = \\sigma([x_i, h^{'}_{n}]W_{h2o})\\\\\n",
    "h_{i+1} = h^{'}_{i}\\\\\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=2\n",
    "embedding_size=3\n",
    "output_size=2\n",
    "\n",
    "embedding = nn.Embedding(input_size, embedding_size)\n",
    "f = Input2Hidden(embedding_size, concat_layers=True)\n",
    "g = Hidden2Output(embedding_size, 2, concat_layers=True)\n",
    "rnn_cell = CustomRNNCell(f,g)\n",
    "\n",
    "model = Model(embedding, rnn_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0  1  0  1  0  1\n",
      "[torch.LongTensor of size 1x6]\n",
      " Variable containing:\n",
      " 1  0  1  0  1  0\n",
      "[torch.LongTensor of size 1x6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_ids = [[0, 1, 0, 1, 0, 1]]\n",
    "target_ids = [[1, 0, 1, 0, 1, 0]]\n",
    "\n",
    "tensor_types = (torch.LongTensor, torch.LongTensor)\n",
    "word_ids_tensor, target_ids_tensor = get_batch(tensor_types, word_ids, target_ids)\n",
    "print(word_ids_tensor, target_ids_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  0.6563  0.1330\n",
       "  0.2257  0.8053\n",
       "  0.6650  0.1079\n",
       "  0.2223  0.8044\n",
       "  0.6657  0.1094\n",
       "  0.2218  0.8047\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0.6563  0.1330\n",
       "  0.2257  0.8053\n",
       "  0.6650  0.1079\n",
       "  0.2223  0.8044\n",
       "  0.6657  0.1094\n",
       "  0.2218  0.8047\n",
       "\n",
       "(2 ,.,.) = \n",
       "  0.6563  0.1330\n",
       "  0.2257  0.8053\n",
       "  0.6650  0.1079\n",
       "  0.2223  0.8044\n",
       "  0.6657  0.1094\n",
       "  0.2218  0.8047\n",
       "[torch.FloatTensor of size 3x6x2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.cat([word_ids_tensor, word_ids_tensor, word_ids_tensor], 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0  1  0  1  0  1\n",
       " 0  1  0  1  0  1\n",
       " 0  1  0  1  0  1\n",
       "[torch.LongTensor of size 3x6]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(torch.cat([word_ids_tensor, word_ids_tensor, word_ids_tensor], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.0142\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model.loss(word_ids_tensor, target_ids_tensor)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0  1  0  1  0  1\n",
       "[torch.LongTensor of size 1x6]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(word_ids_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(max_len=5):\n",
    "    \"\"\"Create a dataset of max_len bits and their flipped values\n",
    "    \n",
    "    Args:\n",
    "        max_len: Maximum number of bits in the number\n",
    "    \"\"\"\n",
    "    max_val = (1<<max_len)\n",
    "    X, Y = [], []\n",
    "    for i in range(max_val):\n",
    "        x = \"{0:0{1}b}\".format(i,max_len)\n",
    "        y = \"{0:0{1}b}\".format((~i) & max_val-1,max_len)\n",
    "        \n",
    "        x = tuple(map(int, x))\n",
    "        y = tuple(map(int, y))\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 10]) torch.Size([1024, 10])\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_dataset(max_len=10)\n",
    "X_tensors, Y_tensors = tuple(map(torch.LongTensor, [X, Y]))\n",
    "print(X_tensors.shape, Y_tensors.shape)\n",
    "assert X_tensors.shape == Y_tensors.shape, \"X and Y should be of same shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data_utils.TensorDataset(X_tensors, Y_tensors)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[002]: loss=0.904; accuracy=0.000%\n",
      "Epoch[004]: loss=0.837; accuracy=0.000%\n",
      "Epoch[006]: loss=0.783; accuracy=0.000%\n",
      "Epoch[008]: loss=0.735; accuracy=0.000%\n",
      "Epoch[010]: loss=0.689; accuracy=50.000%\n",
      "Epoch[012]: loss=0.639; accuracy=100.000%\n",
      "Epoch[014]: loss=0.581; accuracy=100.000%\n",
      "Epoch[016]: loss=0.513; accuracy=100.000%\n",
      "Epoch[018]: loss=0.441; accuracy=100.000%\n",
      "Epoch[020]: loss=0.373; accuracy=100.000%\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learning_rate = 1e-4\n",
    "max_epochs = 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = tensors2variables(X_batch, Y_batch)\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        loss = model.loss(X_batch, Y_batch)\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable weights\n",
    "        # of the model)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "    if epoch % 2 != 0:\n",
    "        continue\n",
    "        \n",
    "    loss = model.loss(*tensors2variables(X_tensors, Y_tensors))\n",
    "    Y_predict = model.predict(Variable(X_tensors)).data\n",
    "    accuracy = (Y_tensors == Y_predict).sum() /operator.mul(*Y_tensors.shape) * 100.\n",
    "    print(\"Epoch[{:03d}]: loss={:5.3f}; accuracy={:.3f}%\".format(epoch, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     0     0     0     1     1     1     1     0     1\n",
       "    1     1     0     0     1     1     0     0     1     0\n",
       "    1     1     0     1     1     1     0     1     0     1\n",
       "    0     0     0     0     1     1     0     0     1     1\n",
       "    1     1     0     0     1     0     0     0     1     0\n",
       "    0     0     1     0     0     0     1     1     0     0\n",
       "    0     0     0     1     0     0     1     1     1     1\n",
       "    0     0     0     0     0     0     0     1     1     1\n",
       "[torch.LongTensor of size 8x10]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict = model.predict(X_batch)\n",
    "Y_predict[:10].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to predict bit shift\n",
    "\n",
    "This example requires some learning of temporal dependencies. We want to learn our network the output when the input $x$'s bits are shifted right by $K$ positions. This can be done using `x >> K`. Similarly, a left shift can be done using `(a << K) & (1<<N) -1)`, where $N$ is the max length of the bit sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(max_len=5, K=4):\n",
    "    \"\"\"Create a dataset of max_len bits and their flipped values\n",
    "    \n",
    "    Args:\n",
    "        max_len: Maximum number of bits in the number\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    max_val = 2**max_len\n",
    "    for i in range(max_val):\n",
    "        x = \"{0:0{1}b}\".format(i,max_len)\n",
    "        y = \"{0:0{1}b}\".format(i>>K,max_len)\n",
    "        \n",
    "        x = tuple(map(int, x))\n",
    "        y = tuple(map(int, y))\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=2\n",
    "embedding_size=3\n",
    "output_size=2\n",
    "\n",
    "embedding = nn.Embedding(input_size, embedding_size)\n",
    "f = Input2Hidden(embedding_size, concat_layers=True)\n",
    "g = Hidden2Output(embedding_size, 2, concat_layers=True)\n",
    "rnn_cell = CustomRNNCell(f,g)\n",
    "\n",
    "model = Model(embedding, rnn_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 10]) torch.Size([1024, 10])\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_dataset(max_len=10, K=4)\n",
    "X_tensors, Y_tensors = tuple(map(torch.LongTensor, [X, Y]))\n",
    "print(X_tensors.shape, Y_tensors.shape)\n",
    "assert X_tensors.shape == Y_tensors.shape, \"X and Y should be of same shape\"\n",
    "\n",
    "train = data_utils.TensorDataset(X_tensors, Y_tensors)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[500]: loss=0.538; accuracy=75.127%\n",
      "Epoch[1000]: loss=0.459; accuracy=83.232%\n",
      "Epoch[1500]: loss=0.409; accuracy=87.041%\n",
      "Epoch[2000]: loss=0.393; accuracy=87.002%\n",
      "Epoch[2500]: loss=0.383; accuracy=87.354%\n",
      "Epoch[3000]: loss=0.377; accuracy=87.793%\n",
      "Epoch[3500]: loss=0.374; accuracy=87.969%\n",
      "Epoch[4000]: loss=0.372; accuracy=87.969%\n",
      "Epoch[4500]: loss=0.366; accuracy=88.213%\n",
      "Epoch[5000]: loss=0.357; accuracy=88.691%\n",
      "Epoch[5500]: loss=0.355; accuracy=88.730%\n",
      "Epoch[6000]: loss=0.354; accuracy=88.809%\n",
      "Epoch[6500]: loss=0.353; accuracy=88.906%\n",
      "Epoch[7000]: loss=0.352; accuracy=88.906%\n",
      "Epoch[7500]: loss=0.351; accuracy=88.887%\n",
      "Epoch[8000]: loss=0.351; accuracy=88.789%\n",
      "Epoch[8500]: loss=0.350; accuracy=88.750%\n",
      "Epoch[9000]: loss=0.348; accuracy=88.672%\n",
      "Epoch[9500]: loss=0.347; accuracy=88.662%\n",
      "Epoch[10000]: loss=0.338; accuracy=88.877%\n",
      "Wall time: 8min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learning_rate = 1e-4\n",
    "max_epochs = 10000\n",
    "check_every=500\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = tensors2variables(X_batch, Y_batch)\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        loss = model.loss(X_batch, Y_batch)\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable weights\n",
    "        # of the model)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "    if epoch % check_every != 0:\n",
    "        continue\n",
    "        \n",
    "    loss = model.loss(*tensors2variables(X_tensors, Y_tensors))\n",
    "    Y_predict = model.predict(Variable(X_tensors)).data\n",
    "    accuracy = (Y_tensors == Y_predict).sum() /operator.mul(*Y_tensors.shape) * 100.\n",
    "    print(\"Epoch[{:03d}]: loss={:5.3f}; accuracy={:.3f}%\".format(epoch, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     0     0     0     0     1     0     0     0     1\n",
       "    0     0     0     0     0     0     1     0     0     0\n",
       "    0     0     0     0     0     1     1     0     0     0\n",
       "    0     0     0     0     1     1     0     0     0     1\n",
       "    0     0     0     0     0     1     0     0     1     1\n",
       "    0     0     0     0     1     0     0     0     1     1\n",
       "    0     0     0     0     0     0     0     0     1     1\n",
       "    0     0     0     0     1     1     0     0     1     1\n",
       "    0     0     0     0     0     0     0     0     0     0\n",
       "    0     0     0     0     0     1     1     0     0     0\n",
       "[torch.LongTensor of size 10x10]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predict = model.predict(X_batch)\n",
    "Y_predict[:10].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Too slow to learn\n",
    "\n",
    "The network trained above takes more than 10,000 epochs to converge to only $90\\%$ accuracy. This reflects a major shortcoming of general RNN's. The shortcoming comes from a problem known as vanishing gradients, where gradients based on more distant steps become numerically too small to update the current layer, leading to information loss and failure to learn long range dependencies. Researcher's have worked around this using what is known as gated or memory based RNN cell's, which allows the information to be stored for a longer duration in the network and the gradients from long range dependencies to flow more easily. Two of the most popular variants are Long Short Term Memory (LSTM) cells and Gated Recurrent Unit (GRU) cells. The core idea is to allow some memory of the current state to be stored for the long time either in a seperate memory cell or in the hidden state. This is usually done by selectively reading and editing from the memory based on the current step. In the following sections we will understand the GRU cells which are a very simple extension of RNN and solve the vanishing gradient problem. The LSTM cells are a bit more involved and will be discussed later. \n",
    "\n",
    "\n",
    "## Gated Recurrent Unit (GRU)\n",
    "The idea behind GRU's is to update part of the hidden state and retain the rest. This is done using the following functions: \n",
    "\n",
    "* reset gate - Identifies what proportion of hidden state should be updated\n",
    "* update gate - Identifies what proportion of hidden state should be reset\n",
    "\n",
    "The implementation is as follow:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "reset = \\sigma(W_{r}[x_i, h_{i-1}])\\\\\n",
    "update = \\sigma(W_{u}[x_i, h_{i-1}])\\\\\n",
    "interim\\_hidden = tanh(W_{i}[x_i, reset \\circ h_{i-1}])\\\\\n",
    "h^{'}_{i} = update \\circ interim\\_hidden + (1-update) \\circ h_{i-1} \\\\\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.Tensor([1,2,3,4]))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.reset_linear = nn.Linear(2*self.input_dim, self.input_dim)\n",
    "        self.update_linear = nn.Linear(2*self.input_dim, self.input_dim)\n",
    "        self.interim_linear = nn.Linear(2*self.input_dim, self.input_dim)\n",
    "        \n",
    "        self.output_linear = nn.Linear(2*self.input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        concat_tensors = torch.cat([x,h], dim=1)\n",
    "        reset = F.sigmoid(self.reset_linear(concat_tensors))\n",
    "        update = F.sigmoid(self.update_linear(concat_tensors))\n",
    "        reset_hidden = reset * h\n",
    "        concat_reset_hidden = torch.cat([x, reset_hidden], dim=1)\n",
    "        interim_hidden = F.tanh(self.interim_linear(concat_reset_hidden))\n",
    "        h_prime = update * interim_hidden + (1-update) * h\n",
    "        \n",
    "        concat_out = torch.cat([x, h_prime], dim=1)\n",
    "        output = F.tanh(self.output_linear(concat_out))\n",
    "        return output, h_prime\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=2\n",
    "embedding_size=3\n",
    "output_size=2\n",
    "\n",
    "embedding = nn.Embedding(input_size, embedding_size)\n",
    "rnn_cell = GRUCell(embedding_size, output_size)\n",
    "\n",
    "model = Model(embedding, rnn_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 10]) torch.Size([1024, 10])\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_dataset(max_len=10, K=4)\n",
    "X_tensors, Y_tensors = tuple(map(torch.LongTensor, [X, Y]))\n",
    "print(X_tensors.shape, Y_tensors.shape)\n",
    "assert X_tensors.shape == Y_tensors.shape, \"X and Y should be of same shape\"\n",
    "\n",
    "train = data_utils.TensorDataset(X_tensors, Y_tensors)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Epoch[500]: loss=0.472; accuracy=77.100%\n",
      "Epoch[1000]: loss=0.435; accuracy=81.387%\n",
      "Epoch[1500]: loss=0.425; accuracy=80.088%\n",
      "Epoch[2000]: loss=0.413; accuracy=82.178%\n",
      "Epoch[2500]: loss=0.403; accuracy=83.369%\n",
      "Epoch[3000]: loss=0.400; accuracy=83.457%\n",
      "Epoch[3500]: loss=0.398; accuracy=83.750%\n",
      "Epoch[4000]: loss=0.397; accuracy=83.789%\n",
      "Epoch[4500]: loss=0.396; accuracy=83.789%\n",
      "Epoch[5000]: loss=0.395; accuracy=83.789%\n",
      "Epoch[5500]: loss=0.395; accuracy=83.691%\n",
      "Epoch[6000]: loss=0.394; accuracy=83.789%\n",
      "Epoch[6500]: loss=0.394; accuracy=83.789%\n",
      "Epoch[7000]: loss=0.393; accuracy=83.789%\n",
      "Epoch[7500]: loss=0.393; accuracy=83.789%\n",
      "Epoch[8000]: loss=0.393; accuracy=83.789%\n",
      "Epoch[8500]: loss=0.393; accuracy=83.750%\n",
      "Epoch[9000]: loss=0.392; accuracy=83.789%\n",
      "Epoch[9500]: loss=0.392; accuracy=83.789%\n",
      "Epoch[10000]: loss=0.390; accuracy=83.945%\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learning_rate = 1e-4\n",
    "max_epochs = 10000\n",
    "check_every=500\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = tensors2variables(X_batch, Y_batch)\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        loss = model.loss(X_batch, Y_batch)\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable weights\n",
    "        # of the model)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "    if epoch % check_every != 0:\n",
    "        continue\n",
    "        \n",
    "    loss = model.loss(*tensors2variables(X_tensors, Y_tensors))\n",
    "    Y_predict = model.predict(Variable(X_tensors)).data\n",
    "    accuracy = (Y_tensors == Y_predict).sum() /operator.mul(*Y_tensors.shape) * 100.\n",
    "    print(\"Epoch[{:03d}]: loss={:5.3f}; accuracy={:.3f}%\".format(epoch, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model (\n",
       "  (embedding): Embedding(2, 3)\n",
       "  (rnn_cell): GRUCell (\n",
       "    (reset_linear): Linear (6 -> 3)\n",
       "    (update_linear): Linear (6 -> 3)\n",
       "    (interim_linear): Linear (6 -> 3)\n",
       "    (output_linear): Linear (6 -> 2)\n",
       "  )\n",
       "  (loss_function): CrossEntropyLoss (\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running using GPU\n",
    "\n",
    "This makes things go faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size=2\n",
    "embedding_size=3\n",
    "output_size=2\n",
    "\n",
    "embedding = nn.Embedding(input_size, embedding_size)\n",
    "rnn_cell = GRUCell(embedding_size, output_size)\n",
    "\n",
    "model = Model(embedding, rnn_cell).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 10]) torch.Size([1024, 10])\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_dataset(max_len=10, K=4)\n",
    "X_tensors, Y_tensors = tuple(map(torch.LongTensor, [X, Y]))\n",
    "print(X_tensors.shape, Y_tensors.shape)\n",
    "assert X_tensors.shape == Y_tensors.shape, \"X and Y should be of same shape\"\n",
    "\n",
    "batch_size=64\n",
    "train = data_utils.TensorDataset(X_tensors, Y_tensors)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0  0  0\n",
       "[torch.cuda.FloatTensor of size 1x3 (GPU 0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_hidden = Variable(torch.zeros(1,model.embedding.embedding_dim))\n",
    "overall_hidden = overall_hidden.cuda()\n",
    "overall_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learning_rate = 1e-4\n",
    "max_epochs = 10000\n",
    "check_every=500\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch = X_batch.cuda(async=True)\n",
    "        Y_batch = Y_batch.cuda(async=True)\n",
    "        X_batch, Y_batch = tensors2variables(X_batch, Y_batch)\n",
    "        hidden = overall_hidden.repeat(batch_size, 1)\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        loss = model.loss(X_batch, Y_batch, hidden=hidden)\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable weights\n",
    "        # of the model)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model\n",
    "        # parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its\n",
    "        # parameters\n",
    "        optimizer.step()\n",
    "    if epoch % check_every != 0:\n",
    "        continue\n",
    "    \n",
    "    hidden = overall_hidden.repeat(X_tensors.shape[0], 1)\n",
    "    loss = model.loss(*tensors2variables(X_tensors.cuda(), Y_tensors.cuda()),\n",
    "                      hidden=hidden)\n",
    "    Y_predict = model.predict(Variable(X_tensors.cuda()), hidden=hidden).data\n",
    "    accuracy = (Y_tensors.cuda() == Y_predict).sum() /operator.mul(*Y_tensors.shape) * 100.\n",
    "    print(\"Epoch[{:03d}]: loss={:5.3f}; accuracy={:.3f}%\".format(epoch, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
